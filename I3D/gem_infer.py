# -*- coding: utf-8 -*-

import streamlit as st
import cv2
import torch
import torch.nn.functional as F
import numpy as np
from pytorch_i3d import InceptionI3d
import torchvision.transforms as transforms
import videotransforms
import time
from collections import Counter
import os
from dotenv import load_dotenv
import requests
import json
from PIL import Image
import base64
from io import BytesIO
from ultralytics import YOLO

# =============================================================================
# CONFIGURATION AND CONSTANTS
# =============================================================================
load_dotenv()

# Model parameters
CLIP_LEN = 64
NUM_CLASSES = 100
WEIGHTS_PATH = "checkpoint/nslt_100_005624_0.756.pt"
MODE = 'rgb'
GLOSS_PATH = r'preprocess/wlasl_class_list.txt'
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

# Gemini API configuration
GEMINI_API_URL = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent?key={GEMINI_API_KEY}"
SEND_TIMEOUT = 10

# Recognition parameters
STRIDE = 5
VOTING_BAG_SIZE = 6
THRESHOLD = 0.605
BACKGROUND_CLASS_ID = -1

# =============================================================================
# STREAMLIT PAGE CONFIGURATION
# =============================================================================
st.set_page_config(
    page_title="ASL Recognition with AI Sentence Generation",
    page_icon="ü§ü",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# Custom CSS matching the HTML design
st.markdown("""
<style>
    .main > div {
        padding-top: 2rem;
        padding-bottom: 2rem;
    }
    
    .stApp {
        background: linear-gradient(135deg, #0f172a 0%, #1e293b 100%);
    }
    
    .video-container {
        background: linear-gradient(180deg,rgba(255,255,255,.03),rgba(255,255,255,.01)), #0b1220;
        border: 1px solid rgba(148,163,184,.18);
        border-radius: 24px;
        padding: 0;
        overflow: hidden;
        box-shadow: 0 10px 25px rgba(0,0,0,.35);
    }
    
    .video-header {
        display: flex;
        align-items: center;
        justify-content: space-between;
        padding: 12px 16px;
        border-bottom: 1px solid rgba(148,163,184,.18);
        background: rgba(255,255,255,.02);
    }
    
    .video-title {
        display: flex;
        align-items: center;
        gap: 10px;
        font-weight: 700;
        color: #e5e7eb;
    }
    
    .status-dot {
        width: 10px;
        height: 10px;
        border-radius: 50%;
        background: #ef4444;
        display: inline-block;
    }
    
    .status-dot.connected {
        background: #22c55e;
        box-shadow: 0 0 10px rgba(34,197,94,.3);
    }
    
    .badge {
        font-size: 12px;
        padding: 4px 8px;
        border-radius: 999px;
        border: 1px solid rgba(148,163,184,.18);
        color: #8ea0b8;
        background: rgba(255,255,255,.03);
        margin: 0 4px;
    }
    
    .badge.ok {
        color: #16a34a;
        border-color: rgba(22,163,74,.45);
    }
    
    .control-panel {
        background: linear-gradient(180deg,rgba(255,255,255,.03),rgba(255,255,255,.01)), #0b1220;
        border: 1px solid rgba(148,163,184,.18);
        border-radius: 24px;
        padding: 16px;
        box-shadow: 0 10px 25px rgba(0,0,0,.35);
    }
    
    .info-panel {
        background: rgba(255,255,255,.03);
        border: 1px solid rgba(148,163,184,.18);
        border-radius: 12px;
        padding: 16px;
        margin: 8px 0;
    }
    
    .info-title {
        font-size: 12px;
        color: #8ea0b8;
        margin-bottom: 8px;
        font-weight: 600;
        text-transform: uppercase;
    }
    
    .info-content {
        font-size: 16px;
        color: #e5e7eb;
        font-family: 'Courier New', monospace;
        min-height: 24px;
        word-break: break-word;
    }
    
    .sentence-display {
        background: linear-gradient(135deg, rgba(34,197,94,.15), rgba(59,130,246,.1));
        border: 2px solid rgba(34,197,94,.3);
    }
    
    .sentence-display .info-content {
        font-weight: 600;
        font-size: 18px;
        color: #22c55e;
    }
    
    .messages-container {
        background: rgba(255,255,255,.02);
        border-radius: 12px;
        padding: 16px;
        max-height: 400px;
        overflow-y: auto;
        margin-top: 16px;
    }
    
    .message {
        margin: 8px 0;
        padding: 12px 16px;
        border-radius: 12px;
        border: 1px solid rgba(148,163,184,.18);
        max-width: 85%;
    }
    
    .message.gloss {
        background: rgba(168,85,247,.12);
        border-color: rgba(168,85,247,.35);
        margin-left: auto;
        font-family: 'Courier New', monospace;
        text-align: right;
        color: #a855f7;
    }
    
    .message.sentence {
        background: rgba(34,197,94,.15);
        border-color: rgba(34,197,94,.4);
        margin: 0 auto;
        font-weight: 600;
        color: #22c55e;
        text-align: center;
    }
    
    .message.system {
        background: rgba(59,130,246,.12);
        border-color: rgba(59,130,246,.35);
        margin: 0 auto;
        color: #3b82f6;
        font-size: 14px;
        text-align: center;
    }
    
    .stats-overlay {
        position: absolute;
        top: 8px;
        left: 8px;
        background: rgba(0,0,0,0.7);
        color: white;
        padding: 6px 10px;
        border-radius: 6px;
        font-size: 11px;
        font-family: monospace;
    }
    
    div[data-testid="stButton"] > button {
        background: linear-gradient(135deg, #22c55e, #3b82f6);
        color: white;
        border: none;
        border-radius: 10px;
        padding: 8px 16px;
        font-weight: 600;
        transition: all 0.2s ease;
    }
    
    div[data-testid="stButton"] > button:hover {
        transform: translateY(-1px);
        box-shadow: 0 4px 12px rgba(34,197,94,.3);
    }
    
    .secondary-btn > button {
        background: linear-gradient(135deg, #f59e0b, #d97706) !important;
    }
    
    .danger-btn > button {
        background: linear-gradient(135deg, #ef4444, #dc2626) !important;
    }
</style>
""", unsafe_allow_html=True)

# =============================================================================
# SESSION STATE INITIALIZATION
# =============================================================================
if 'glosses_buffer' not in st.session_state:
    st.session_state.glosses_buffer = []

if 'model' not in st.session_state:
    st.session_state.model = None

if 'gloss_map' not in st.session_state:
    st.session_state.gloss_map = {}

if 'frame_buffer' not in st.session_state:
    st.session_state.frame_buffer = []

if 'raw_predictions_queue' not in st.session_state:
    st.session_state.raw_predictions_queue = []

if 'last_confirmed_class_id' not in st.session_state:
    st.session_state.last_confirmed_class_id = None

if 'confirmed_gloss_text' not in st.session_state:
    st.session_state.confirmed_gloss_text = ""

if 'frame_counter' not in st.session_state:
    st.session_state.frame_counter = 0

if 'generated_sentences' not in st.session_state:
    st.session_state.generated_sentences = []

if 'messages' not in st.session_state:
    st.session_state.messages = []

if 'camera_active' not in st.session_state:
    st.session_state.camera_active = False

if 'ai_connected' not in st.session_state:
    st.session_state.ai_connected = False

if 'current_sentence' not in st.session_state:
    st.session_state.current_sentence = "Ready to generate..."

# =============================================================================
# UTILITY FUNCTIONS
# =============================================================================
@st.experimental_singleton
def load_gloss_map(path):
    """Load gloss mapping from file"""
    gloss_map = {}
    try:
        with open(path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                parts = line.split()
                if len(parts) < 2:
                    continue
                class_id = int(parts[0])
                gloss = ' '.join(parts[1:])
                gloss_map[class_id] = gloss
    except FileNotFoundError:
        st.error(f"Gloss file not found: {path}")
        st.stop()
    return gloss_map

@st.experimental_singleton
def load_model():
    """Load the I3D model"""
    try:
        with st.spinner("Loading I3D model..."):
            model = InceptionI3d(400, in_channels=3)
            model.load_state_dict(torch.load('weights/rgb_imagenet.pt', map_location='cpu'))
            model.replace_logits(NUM_CLASSES)
            model.load_state_dict(torch.load(WEIGHTS_PATH, map_location='cpu'))
            if torch.cuda.is_available():
                model.cuda()
            model = torch.nn.DataParallel(model)
            model.eval()
            return model
    except Exception as e:
        st.error(f"Error loading model: {e}")
        return None

def preprocess_frame(frame):
    """Preprocess frame for model input"""
    frame = cv2.resize(frame, (224, 224))
    frame = (frame / 255.0) * 2 - 1
    return frame

def frames_to_tensor(frames):
    """Convert frames list to tensor"""
    transform = transforms.Compose([videotransforms.CenterCrop(224)])
    frames_np = np.stack(frames, axis=0)
    frames_np = np.transpose(frames_np, (3, 0, 1, 2))
    frames_tensor = torch.from_numpy(frames_np).float()
    frames_tensor = transform(frames_tensor)
    frames_tensor = frames_tensor.unsqueeze(0)
    
    if torch.cuda.is_available():
        return frames_tensor.cuda()
    return frames_tensor

def send_gemini_request(glosses_list):
    """Send glosses to Gemini API and get a meaningful sentence"""
    if not GEMINI_API_KEY:
        return "Error: GEMINI_API_KEY not found!"
    
    try:
        glosses_text = " ".join(glosses_list)
        prompt = f"""You are a sign language interpreter. I will give you a sequence of sign language glosses (individual sign words), and you need to convert them into a natural, grammatically correct English sentence that conveys the intended meaning.

Glosses: {glosses_text}

Please provide a natural English sentence that represents what the person is trying to communicate through these signs. Focus on the meaning rather than literal word order, as sign language grammar differs from English grammar.

Respond with only the sentence, no additional explanation."""

        payload = {
            "contents": [{"parts": [{"text": prompt}]}],
            "generationConfig": {
                "temperature": 0.3,
                "topK": 40,
                "topP": 0.95,
                "maxOutputTokens": 100,
            }
        }

        headers = {"Content-Type": "application/json"}
        
        response = requests.post(GEMINI_API_URL, 
                               json=payload, 
                               headers=headers, 
                               timeout=SEND_TIMEOUT)
        
        if response.status_code == 200:
            result = response.json()
            if 'candidates' in result and len(result['candidates']) > 0:
                sentence = result['candidates'][0]['content']['parts'][0]['text'].strip()
                return sentence
            else:
                return "Gemini: No response generated"
        else:
            return f"Gemini HTTP {response.status_code}"
            
    except Exception as e:
        return f"Error: {str(e)}"

def add_message(text, msg_type='system'):
    """Add message to session state"""
    timestamp = time.strftime("%H:%M:%S")
    st.session_state.messages.append({
        'text': text,
        'type': msg_type,
        'timestamp': timestamp
    })

def process_frame_for_recognition(frame):
    """Process frame and return recognition result"""
    if st.session_state.model is None:
        return None
        
    frame_proc = preprocess_frame(frame)
    st.session_state.frame_buffer.append(frame_proc)
    
    if len(st.session_state.frame_buffer) > CLIP_LEN:
        st.session_state.frame_buffer.pop(0)
    
    st.session_state.frame_counter += 1
    
    if len(st.session_state.frame_buffer) == CLIP_LEN and st.session_state.frame_counter % STRIDE == 0:
        with torch.no_grad():
            input_tensor = frames_to_tensor(st.session_state.frame_buffer)
            logits = st.session_state.model(input_tensor)
            predictions = torch.max(logits, dim=2)[0]
            probs = F.softmax(predictions, dim=1)
            max_prob, pred_class = torch.max(probs, dim=1)
            pred_class_id = pred_class.item()
            max_prob_val = max_prob.item()

            if max_prob_val >= THRESHOLD:
                st.session_state.raw_predictions_queue.append(pred_class_id)
            else:
                st.session_state.raw_predictions_queue.append(BACKGROUND_CLASS_ID)

            if len(st.session_state.raw_predictions_queue) > VOTING_BAG_SIZE:
                st.session_state.raw_predictions_queue.pop(0)

        if len(st.session_state.raw_predictions_queue) == VOTING_BAG_SIZE:
            vote_counts = Counter(st.session_state.raw_predictions_queue)
            majority_class_id, max_count = vote_counts.most_common(1)[0]
            if majority_class_id != BACKGROUND_CLASS_ID and max_count > VOTING_BAG_SIZE / 2:
                if majority_class_id != st.session_state.last_confirmed_class_id:
                    gloss = st.session_state.gloss_map.get(majority_class_id, f'Class_{majority_class_id}')
                    st.session_state.confirmed_gloss_text = gloss
                    st.session_state.last_confirmed_class_id = majority_class_id
                    
                    st.session_state.glosses_buffer.append(gloss)
                    add_message(f"Recognized: {gloss}", 'gloss')
                    st.session_state.raw_predictions_queue = []
                    return gloss
            else:
                st.session_state.confirmed_gloss_text = ""
                st.session_state.last_confirmed_class_id = None
    
    return None
# if "yolo_seg" not in st.session_state:
#     st.session_state.yolo_seg = YOLO("yolov8m-seg.pt")

# H√†m segment ng∆∞·ªùi + thay background
def segment_person(frame, bg_color=(0, 0, 139)):
    # results = st.session_state.yolo_seg(frame, verbose=False)
    # output = np.full_like(frame, bg_color, dtype=np.uint8)

    # for r in results:
    #     if r.masks is not None:
    #         for mask, cls in zip(r.masks.data, r.boxes.cls):
    #             if int(cls) == 0:  # "person"
    #                 mask = mask.cpu().numpy()
    #                 mask = cv2.resize(mask, (frame.shape[1], frame.shape[0]))
    #                 mask = (mask > 0.4).astype(np.uint8)
    #                 for c in range(3):
    #                     output[:, :, c] = frame[:, :, c] * mask + output[:, :, c] * (1 - mask)

    return frame

# =============================================================================
# MAIN APP
# =============================================================================from ultralytics import YOLO

# Load YOLOv8-small segmentation model (once)



def main():
    # --- Global CSS (font setup) ---
    st.markdown("""
    <style>
        * {
            font-family: "Segoe UI", "Roboto", "Helvetica", sans-serif;
        }
        .info-title {
            font-weight: 600;
            font-size: 16px;
        }
        .info-content {
            font-size: 14px;
        }
        .messages-container {
            font-size: 13px;
        }
    </style>
    """, unsafe_allow_html=True)

    # Header
    st.markdown("""
    <div class="video-header" style="margin-bottom: 20px;">
        <div class="video-title">
            <span class="status-dot connected"></span>
            <span>ASL Recognition with AI Sentence Generation</span>
        </div>
        <div>
            <span class="badge ok">I3D Ready</span>
            <span class="badge ok">Gemini Ready</span>
        </div>
    </div>
    """, unsafe_allow_html=True)
    fps_time = time.time()
    fps_count = 0
    fps = 0

    # Check API key
    if not GEMINI_API_KEY:
        st.error("‚ö†Ô∏è GEMINI_API_KEY not found! Please create a .env file with your API key.")
        st.markdown("Get your API key at: https://makersuite.google.com/app/apikey")
        return

    # Load model + gloss map
    if st.session_state.model is None:
        st.session_state.model = load_model()
        st.session_state.gloss_map = load_gloss_map(GLOSS_PATH)
        if st.session_state.model is not None:
            add_message("AI models loaded successfully!", 'system')

    # Init session state
    if "capture_active" not in st.session_state:
        st.session_state.capture_active = False
    if "frame_counter" not in st.session_state:
        st.session_state.frame_counter = 0
    if "frame_buffer" not in st.session_state:
        st.session_state.frame_buffer = []
    if "raw_predictions_queue" not in st.session_state:
        st.session_state.raw_predictions_queue = []
    if "last_confirmed_class_id" not in st.session_state:
        st.session_state.last_confirmed_class_id = None
    if "confirmed_gloss_text" not in st.session_state:
        st.session_state.confirmed_gloss_text = ""

    # Layout
    col1, col2 = st.columns([1.1, 0.9])

    with col1:
        st.markdown('<div class="video-container">', unsafe_allow_html=True)

        # --- Toggle Start/Stop button ---
        if st.button("‚ñ∂Ô∏è Start / ‚èπ Stop"):
            if st.session_state.capture_active:
                # Stop
                st.session_state.capture_active = False
                st.session_state.frame_buffer = []
                st.session_state.raw_predictions_queue = []
                st.session_state.last_confirmed_class_id = None
                st.success("üõë Capture stopped, buffers reset.")
            else:
                # Start
                st.session_state.capture_active = True
                st.session_state.frame_buffer = []
                st.session_state.raw_predictions_queue = []
                st.session_state.glosses_buffer = []
                st.session_state.last_confirmed_class_id = None
                st.session_state.frame_counter = 0
                st.success("‚ñ∂Ô∏è Capture started.")

        # --- Camera loop ---
        frame_placeholder = st.empty()
        if st.session_state.capture_active:
            cap = cv2.VideoCapture(0)
            if not cap.isOpened():
                st.error("Kh√¥ng m·ªü ƒë∆∞·ª£c camera. Vui l√≤ng ki·ªÉm tra thi·∫øt b·ªã.")
                return

            while st.session_state.capture_active:
                ret, frame = cap.read()
                if not ret:
                    st.warning("Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c frame t·ª´ camera.")
                    break

                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

                # --- Segment + replace background ---
                frame_processed = segment_person(frame_rgb)
                fps_count += 1
                if time.time() - fps_time >= 1.0:
                    fps = fps_count
                    fps_count = 0
                    fps_time = time.time()
                # Recognition
                recognized_gloss = process_frame_for_recognition(frame_processed)
                display_frame = frame_processed.copy()

                # Hi·ªÉn th·ªã video
                cv2.putText(display_frame, f'FPS: {fps}', (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
                frame_placeholder.image(display_frame, channels="RGB")

                # Hi·ªÉn th·ªã gloss n·∫øu c√≥
                if recognized_gloss:
                    st.success(f"Recognized gloss: {recognized_gloss}")

            cap.release()

        st.markdown('</div>', unsafe_allow_html=True)

        st.markdown(f"""
        <div class="info-panel">
            <div class="info-title">System Status</div>
            <div class="info-content">
                Capture: {"Active" if st.session_state.capture_active else "Stopped"} | 
                Glosses Collected: {len(st.session_state.glosses_buffer)} | 
                Sentences Generated: {len(st.session_state.generated_sentences) if 'generated_sentences' in st.session_state else 0}
            </div>
        </div>
        """, unsafe_allow_html=True)

    # --- Control buttons ---
    spacer1, spacer2, col_btn1, col_btn2 = st.columns([1.1, 0.9, 1, 1])

    with col_btn1:
        if st.button("ü§ñ Generate Sentence", disabled=len(st.session_state.glosses_buffer) == 0):
            if st.session_state.glosses_buffer:
                with st.spinner("Generating sentence..."):
                    sentence = send_gemini_request(st.session_state.glosses_buffer)
                    st.session_state.current_sentence = sentence
                    if "generated_sentences" not in st.session_state:
                        st.session_state.generated_sentences = []
                    st.session_state.generated_sentences.append({
                        "glosses": list(st.session_state.glosses_buffer),
                        "sentence": sentence,
                        "timestamp": time.strftime("%H:%M:%S")
                    })
                    add_message(sentence, 'sentence')
                st.success("‚úÖ Sentence generated!")

    with col_btn2:
        if st.button("üîÑ Reset All"):
            st.session_state.glosses_buffer = []
            st.session_state.messages = []
            st.session_state.generated_sentences = []
            st.session_state.current_sentence = "Ready to generate..."
            st.session_state.frame_buffer = []
            st.session_state.raw_predictions_queue = []
            st.session_state.last_confirmed_class_id = None
            st.session_state.capture_active = False
            st.success("üîÑ Session reset!")

    # --- Right panel ---
    with col2:
        st.markdown('<div class="control-panel">', unsafe_allow_html=True)

        st.markdown(f"""
        <div class="info-panel">
            <div class="info-title">Current Glosses ({len(st.session_state.glosses_buffer)})</div>
            <div class="info-content">{' '.join(st.session_state.glosses_buffer) if st.session_state.glosses_buffer else 'No glosses collected yet'}</div>
        </div>
        """, unsafe_allow_html=True)

        st.markdown(f"""
        <div class="info-panel sentence-display">
            <div class="info-title">Latest Generated Sentence</div>
            <div class="info-content">{st.session_state.current_sentence if 'current_sentence' in st.session_state else 'Ready to generate...'}</div>
        </div>
        """, unsafe_allow_html=True)

        st.markdown('<div class="messages-container">', unsafe_allow_html=True)
        st.markdown("**Activity Log:**")

        for msg in st.session_state.messages[-10:]:
            msg_class = f"message {msg['type']}"
            if msg['type'] == 'gloss':
                content = f"**Gloss:** {msg['text']}"
            elif msg['type'] == 'sentence':
                content = f"**Generated:** \"{msg['text']}\""
            else:
                content = msg['text']

            st.markdown(f"""
            <div class="{msg_class}">
                <small>{msg['timestamp']}</small><br>
                {content}
            </div>
            """, unsafe_allow_html=True)

        st.markdown('</div>', unsafe_allow_html=True)
        st.markdown('</div>', unsafe_allow_html=True)

    # --- Instructions ---
    with st.expander("üìã How to Use"):
        st.markdown("""
        **Getting Started:**
        1. B·∫•m "Start / Stop" ƒë·ªÉ b·∫≠t camera v√† b·∫Øt ƒë·∫ßu capture
        2. Khi capture ƒëang ch·∫°y ‚Üí h·ªá th·ªëng s·∫Ω gom glosses b·∫±ng sliding window
        3. B·∫•m "Start / Stop" l·∫ßn n·ªØa ƒë·ªÉ d·ª´ng capture
        4. Nh·∫•n "Generate Sentence" ƒë·ªÉ g·ª≠i glosses sang Gemini v√† sinh c√¢u
        5. D√πng "Reset All" ƒë·ªÉ x√≥a to√†n b·ªô d·ªØ li·ªáu c≈©

        **Tips:**
        - C·∫ßn ƒë·ªß 64 frames ƒë·ªÉ model I3D predict ƒë∆∞·ª£c gloss
        - H·ªá th·ªëng ch·ªâ hi·ªÉn th·ªã gloss khi ƒë√£ ƒë∆∞·ª£c confirm qua voting bag
        - Reset All n·∫øu mu·ªën b·∫Øt ƒë·∫ßu l·∫°i t·ª´ ƒë·∫ßu
        """)

if __name__ == '__main__':
    main()